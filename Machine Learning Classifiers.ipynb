{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470d90f8-5e7b-4a1f-a790-1e0d9b7dab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc, \n",
    "    precision_recall_curve, classification_report, cohen_kappa_score, log_loss\n",
    ")\n",
    "\n",
    "X = data.drop([], axis = 1)\n",
    "y = data[]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB(),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "accuracy  = []\n",
    "for name, classifier in classifiers.items():\n",
    "    print(\"Classification Report of \", classifier)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    #Accuracy\n",
    "    current_accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy.append(current_accuracy)\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    \n",
    "    # Precision, Recall, F1-Score (for multiclass)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    # Cohen's Kappa\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    print(f\"Cohen's Kappa: {kappa:.2f}\")\n",
    "    \n",
    "    # For multiclass, we need to handle probabilities differently if available.\n",
    "    if hasattr(classifier, \"predict_proba\"):\n",
    "        # Predict probabilities\n",
    "        y_proba = classifier.predict_proba(X_test)\n",
    "        \n",
    "        # Log Loss (for multiclass)\n",
    "        loss = log_loss(y_test, y_proba)\n",
    "        print(f\"Log Loss: {loss:.2f}\")\n",
    "        \n",
    "        # ROC Curve and AUC for multiclass\n",
    "        fpr = {}\n",
    "        tpr = {}\n",
    "        roc_auc = {}\n",
    "        n_classes = y_proba.shape[1]\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test == i, y_proba[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "        # Plot ROC curves\n",
    "        plt.figure()\n",
    "        colors = ['aqua', 'darkorange', 'cornflowerblue']\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(fpr[i], tpr[i], color=color, lw=2, \n",
    "                     label=f'ROC curve of class {i} (area = {roc_auc[i]:.2f})')\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic for Multiclass')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "        # Precision-Recall Curve for multiclass\n",
    "        precision_vals = {}\n",
    "        recall_vals = {}\n",
    "        for i in range(n_classes):\n",
    "            precision_vals[i], recall_vals[i], _ = precision_recall_curve(y_test == i, y_proba[:, i])\n",
    "        \n",
    "        plt.figure()\n",
    "        for i, color in zip(range(n_classes), colors):\n",
    "            plt.plot(recall_vals[i], precision_vals[i], color=color, lw=2,\n",
    "                     label=f'Precision-Recall curve of class {i}')\n",
    "        \n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve for Multiclass')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.show()\n",
    "\n",
    "print('Comparison of Accuracy')\n",
    "performance_df = pd.DataFrame({'Model' : classifiers.keys(), 'Accuracy' : accuracy})\n",
    "print(performance_df)\n",
    "g = sns.catplot(x = 'Model', y = 'Accuracy', data = performance_df, kind = 'bar', height = 5)\n",
    "g.set_xticklabels(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a9611-04c0-402d-ab04-e54561935878",
   "metadata": {},
   "source": [
    "## Lazy predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec471bb-3cf9-43a8-b25b-70951b349e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "df = pd.DataFrame(models)\n",
    "print(df.to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
